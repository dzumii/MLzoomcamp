{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4839e38a",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "The dataset contains around 2500 images of bees and around 2100 images of wasps.\n",
    "\n",
    "The dataset contains separate folders for training and test sets.\n",
    "\n",
    "Model\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "The shape for input should be (150, 150, 3)\n",
    "Next, create a convolutional layer (Conv2D):\n",
    "Use 32 filters\n",
    "Kernel size should be (3, 3) (that's the size of the filter)\n",
    "Use 'relu' as activation\n",
    "Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "Set the pooling size to (2, 2)\n",
    "Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "As optimizer use SGD with the following parameters:\n",
    "\n",
    "SGD(lr=0.002, momentum=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f11bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.xception import preprocess_input\n",
    "# from keras.applications import Xception\n",
    "# from keras import layers\n",
    "# from keras import models\n",
    "# from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92295c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab9b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27656bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373fe68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfee8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size for the inner dense layer\n",
    "size_inner = 64\n",
    "\n",
    "#the learning rate\n",
    "learning_rate = 0.002\n",
    "\n",
    "\n",
    "\n",
    "base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "#vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "conv_layer = layers.Conv2D(32, (3, 3), activation='relu')(base)\n",
    "pooling_layer = layers.MaxPooling2D((2, 2))(conv_layer)\n",
    "flattened = layers.Flatten()(pooling_layer)\n",
    "inner = layers.Dense(units=size_inner, activation='relu')(flattened) \n",
    "#inner = keras.layers.Dense(size_inner=64, activation='relu')(flattened) \n",
    "#outputs = keras.layers.Dense(10)(inner)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(inner)\n",
    "#model = keras.Model(inputs, outputs)\n",
    "model = models.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "#optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer = optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "#loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0593518",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Since we have a binary classification problem, what is the best loss function for us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd3962",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the summary method for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b71c3c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 3, 3, 32)          589856    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21453513 (81.84 MB)\n",
      "Trainable params: 592033 (2.26 MB)\n",
      "Non-trainable params: 20861480 (79.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21771241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 3, 3, 32)          589856    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21453513 (81.84 MB)\n",
      "Trainable params: 592033 (2.26 MB)\n",
      "Non-trainable params: 20861480 (79.58 MB)\n",
      "_________________________________________________________________\n",
      "Number of parameters in the convolutional layer: 589856\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "conv_layer_params = model.layers[2].count_params()  #the Conv2D layer is the third layer\n",
    "print(\"Number of parameters in the convolutional layer:\", conv_layer_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70349ac",
   "metadata": {},
   "source": [
    "## Generators and Training\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "We don't need to do any additional pre-processing for the images.\n",
    "When reading the data from train/test directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "Use batch_size=20\n",
    "Use shuffle=True for both training and test sets.\n",
    "For training use .fit() with the following params:\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "Question 3\n",
    "What is the median of training accuracy for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3970b981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "                               rescale=1./255)\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "                             rescale=1./255)\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd44447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'categorical'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b2ca1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'categorical'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a7ce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 82s 430ms/step - loss: 0.3123 - accuracy: 0.8648 - val_loss: 0.2128 - val_accuracy: 0.9205\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 78s 427ms/step - loss: 0.2296 - accuracy: 0.9111 - val_loss: 0.2152 - val_accuracy: 0.9150\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 79s 431ms/step - loss: 0.1925 - accuracy: 0.9244 - val_loss: 0.2279 - val_accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 79s 429ms/step - loss: 0.1640 - accuracy: 0.9372 - val_loss: 0.1990 - val_accuracy: 0.9194\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 79s 430ms/step - loss: 0.1451 - accuracy: 0.9448 - val_loss: 0.2066 - val_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 79s 430ms/step - loss: 0.1226 - accuracy: 0.9546 - val_loss: 0.2218 - val_accuracy: 0.9139\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 79s 428ms/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.2396 - val_accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 79s 429ms/step - loss: 0.0781 - accuracy: 0.9720 - val_loss: 0.2402 - val_accuracy: 0.9183\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 78s 423ms/step - loss: 0.0659 - accuracy: 0.9755 - val_loss: 0.2494 - val_accuracy: 0.9183\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 78s 425ms/step - loss: 0.0512 - accuracy: 0.9859 - val_loss: 0.2658 - val_accuracy: 0.9150\n"
     ]
    }
   ],
   "source": [
    "#size for the inner dense layer\n",
    "size_inner = 64\n",
    "\n",
    "#the learning rate\n",
    "learning_rate = 0.002\n",
    "\n",
    "\n",
    "\n",
    "base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "#vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "conv_layer = layers.Conv2D(32, (3, 3), activation='relu')(base)\n",
    "pooling_layer = layers.MaxPooling2D((2, 2))(conv_layer)\n",
    "flattened = layers.Flatten()(pooling_layer)\n",
    "inner = layers.Dense(units=size_inner, activation='relu')(flattened) \n",
    "#inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "#outputs = keras.layers.Dense(10)(inner)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(inner)\n",
    "#model = keras.Model(inputs, outputs)\n",
    "model = models.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "#optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer = optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "#loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da957b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of training accuracy: 0.9496872425079346\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "training_loss = history.history['loss']\n",
    "\n",
    "\n",
    "median_training_accuracy = np.median(training_accuracy)\n",
    "print(\"Median of training accuracy:\", median_training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847a35f",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "What is the standard deviation of training loss for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa9fff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of training loss: 0.07742216594427309\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard deviation of training loss\n",
    "std_training_loss = np.std(training_loss)\n",
    "print(\"Standard deviation of training loss:\", std_training_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab07d9e",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "rotation_range=50,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1,\n",
    "zoom_range=0.1,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest'\n",
    "Question 5\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "Note: make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3d7b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                              rotation_range=50,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                zoom_range=0.1,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "                             rescale=1./255)\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e6ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 96s 522ms/step - loss: 0.2869 - accuracy: 0.8809 - val_loss: 0.2142 - val_accuracy: 0.9139\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 92s 498ms/step - loss: 0.2465 - accuracy: 0.8999 - val_loss: 0.2244 - val_accuracy: 0.9237\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 86s 470ms/step - loss: 0.2342 - accuracy: 0.9070 - val_loss: 0.2331 - val_accuracy: 0.9227\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 86s 468ms/step - loss: 0.2278 - accuracy: 0.9064 - val_loss: 0.2067 - val_accuracy: 0.9248\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 85s 463ms/step - loss: 0.2286 - accuracy: 0.9083 - val_loss: 0.2070 - val_accuracy: 0.9248\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 85s 461ms/step - loss: 0.2109 - accuracy: 0.9151 - val_loss: 0.2195 - val_accuracy: 0.9248\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 85s 463ms/step - loss: 0.2074 - accuracy: 0.9108 - val_loss: 0.2206 - val_accuracy: 0.9281\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 0.2037 - accuracy: 0.9138 - val_loss: 0.2313 - val_accuracy: 0.9227\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 93s 503ms/step - loss: 0.1968 - accuracy: 0.9171 - val_loss: 0.2272 - val_accuracy: 0.9281\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 86s 468ms/step - loss: 0.2080 - accuracy: 0.9192 - val_loss: 0.2100 - val_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "319ea248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test loss for all epochs: 0.21940127164125442\n"
     ]
    }
   ],
   "source": [
    "# Extract test loss and accuracy from the history object\n",
    "test_loss = history.history['val_loss']\n",
    "test_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Calculate the mean of test loss for all epochs\n",
    "mean_test_loss= np.mean(test_loss)\n",
    "print(\"Mean of test loss for all epochs:\", mean_test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc21714",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fbb3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of test accuracy for the last 5 epochs: 0.9248365998268128\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average of test accuracy for the last 5 epochs\n",
    "average_test_accuracy_last5 = np.mean(test_accuracy[-5:])\n",
    "print(\"Average of test accuracy for the last 5 epochs:\", average_test_accuracy_last5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948594cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
